# -*- coding: utf-8 -*-
"""BCA_scrap.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1b4VUJZ1fyqHFDbUOEspbKZpLDsys8t8L
"""

!pip install playwright nest_asyncio openai pydantic tabulate
!playwright install chromium

import asyncio
import nest_asyncio
from typing import List, Optional

from playwright.async_api import async_playwright
from pydantic import BaseModel
from google.colab import userdata
from openai import OpenAI

# Allow nested event loops in Colab
nest_asyncio.apply()

# OpenAI client (cheap model)
OPENAI_API_KEY = userdata.get("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

class WebScraperActor:
    def __init__(self):
        self.playwright = None
        self.browser = None
        self.page = None

    async def init_browser(self):
        if self.playwright is None:
            self.playwright = await async_playwright().start()
        if self.browser is None:
            self.browser = await self.playwright.chromium.launch(
                headless=True,
                args=[
                    "--disable-dev-shm-usage",
                    "--no-sandbox",
                    "--disable-setuid-sandbox",
                    "--disable-gpu",
                ],
            )+
        if self.page is None or self.page.is_closed():
            self.page = await self.browser.new_page()

    async def goto(self, url: str) -> str:
        await self.init_browser()
        await self.page.goto(url, wait_until="load")
        # small wait to allow dynamic content
        await self.page.wait_for_timeout(1500)
        return await self.page.content()

    async def click(self, selector: str) -> str:
        """
        selector can be any Playwright selector, e.g.:
        - 'text="Volume Two"'
        - 'a[href*="volume-two"]'
        - 'role=link[name="Volume Two"i]'
        """
        await self.init_browser()
        await self.page.click(selector)
        await self.page.wait_for_timeout(1500)
        return await self.page.content()

    async def extract_html(self) -> str:
        await self.init_browser()
        return await self.page.content()

    async def screenshot(self, path="page.png") -> str:
        await self.init_browser()
        await self.page.screenshot(path=path, full_page=True)
        return path

    async def screenshot_bytes(self) -> bytes:
        await self.init_browser()
        return await self.page.screenshot(full_page=True)

    async def close(self):
        try:
            if self.browser is not None:
                await self.browser.close()
        except Exception:
            pass
        try:
            if self.playwright is not None:
                await self.playwright.stop()
        except Exception:
            pass
        self.playwright = None
        self.browser = None
        self.page = None

class BCARequirement(BaseModel):
    category: str                     # e.g. "Stairs", "Balustrades", "Fire separation"
    code_reference: Optional[str]     # e.g. "NCC 2022 Vol 2 Part 3.9.1, Clause 3.9.1.1"
    requirement: str                  # plain-language requirement
    applicability: Optional[str]      # when/where it applies (Class, storeys, etc.)
    notes: Optional[str] = None       # clarifications, assumptions


class BCARequirementReport(BaseModel):
    task: str
    assumed_location: str             # e.g. "Australia, NCC 2022"
    assumed_volume: Optional[str]     # "Volume One", "Volume Two", etc.
    assumptions: List[str]            # key assumptions the model made
    requirements: List[BCARequirement]

ALLOWED_ACTIONS = """
You may ONLY respond with exactly ONE of the following actions (no explanation):

NAVIGATE <url>
CLICK <selector>
EXTRACT
FINISH
"""

AGENT_SYSTEM_PROMPT = f"""
You are an autonomous web agent that navigates the National Construction Code (NCC)
/ Building Code of Australia (BCA) website at https://ncc.abcb.gov.au/.

Your job is to:
1. Read the current rendered HTML of the page.
2. Decide the best next action to move towards answering the user's building code task.
3. Determine which NCC Volume / Part / Clause is relevant.
4. When you have reached a page that contains the key code requirements, issue EXTRACT.
5. If you are truly finished and have nothing more to extract, issue FINISH.

You control a headless browser that can:
- NAVIGATE <url>  (go to an absolute or relative URL)
- CLICK <selector> (click a link/button/etc. using Playwright selector syntax)
- EXTRACT         (tell the controller to return the current HTML)
- FINISH          (stop the agent loop)

Rules:
- Stay within ncc.abcb.gov.au.
- Prefer NAVIGATE for obvious URLs (e.g. direct links to volumes, parts).
- Use CLICK when you need to expand menus, open parts/chapters, or follow links.
- When in doubt, first navigate to NCC 2022 and the correct volume based on the task.
- Think step-by-step, but DO NOT output your thinking, only actions.

{ALLOWED_ACTIONS}
"""

async def llm_choose_action(current_html: str, history: List[str], user_task: str) -> str:
    """
    Ask gpt-4o-mini to choose the next agent action.
    Returns a string like:
      - 'NAVIGATE https://ncc.abcb.gov.au/...'
      - 'CLICK text="Volume Two"'
      - 'EXTRACT'
      - 'FINISH'
    """
    html_snippet = current_html[:8000]  # keep it within reasonable token budget
    history_text = "\n".join(history[-10:])  # last 10 actions

    resp = client.chat.completions.create(
        model="gpt-4o-mini-2024-07-18",
        temperature=0.1,
        messages=[
            {"role": "system", "content": AGENT_SYSTEM_PROMPT},
            {"role": "user", "content": f"USER TASK: {user_task}"},
            {
                "role": "assistant",
                "content": f"RECENT ACTIONS:\n{history_text if history_text else '(none)'}",
            },
            {
                "role": "assistant",
                "content": f"CURRENT PAGE HTML (truncated):\n{html_snippet}",
            },
        ],
    )

    action = resp.choices[0].message.content.strip()
    return action

import asyncio
import nest_asyncio
from typing import List, Optional, Tuple

from playwright.async_api import async_playwright
from pydantic import BaseModel
from google.colab import userdata
from openai import OpenAI

# Allow nested event loops in Colab
nest_asyncio.apply()

# OpenAI client (cheap model)
OPENAI_API_KEY = userdata.get("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY)

async def ncc_bca_agent_get_html(user_task: str, max_steps: int = 10) -> Tuple[str, bytes]:
    """
    Agentic loop:
    - Starts at NCC homepage
    - Lets the LLM decide actions
    - Returns the final extracted HTML (from EXTRACT or FINISH) and a screenshot.
    """
    scraper = WebScraperActor()
    start_url = "https://ncc.abcb.gov.au/"

    # initial page
    html = await scraper.goto(start_url)
    history: List[str] = []

    try:
        for step in range(1, max_steps + 1):
            print(f"\n=== STEP {step} ===")

            action = await llm_choose_action(html, history, user_task)
            history.append(action)
            print("Agent action:", action)

            upper = action.upper().strip()

            if upper.startswith("NAVIGATE "):
                # Extract URL after 'NAVIGATE '
                raw_url = action[len("NAVIGATE "):].strip()
                if not raw_url.startswith("http"):
                    # handle relative paths
                    if raw_url.startswith("/"):
                        raw_url = "https://ncc.abcb.gov.au" + raw_url
                    else:
                        raw_url = "https://ncc.abcb.gov.au/" + raw_url
                print("Navigating to:", raw_url)
                html = await scraper.goto(raw_url)
                continue

            if upper.startswith("CLICK "):
                selector = action[len("CLICK "):].strip()
                print("Clicking selector:", selector)
                html = await scraper.click(selector)
                continue

            if "EXTRACT" in upper:
                print("Extracting current page HTML and screenshot...")
                html = await scraper.extract_html()
                screenshot_bytes = await scraper.screenshot_bytes()
                return html, screenshot_bytes

            if "FINISH" in upper:
                print("Agent indicated FINISH. Returning current HTML and a blank screenshot.")
                return html, b''

            # Fallback: unknown action, stop to avoid infinite loop
            print("Unknown action. Stopping agent loop. Returning current HTML and a blank screenshot.")
            return html, b''

        print("\nMax steps reached. Returning current HTML and a blank screenshot.")
        return html, b''

    finally:
        await scraper.close()

def summarize_bca_requirements(html: str, user_task: str) -> BCARequirementReport:
    """
    Takes the final NCC HTML retrieved by the agent and returns
    a structured BCARequirementReport using gpt-4o-mini.
    """
    html_snippet = html[:15000]  # keep under token limits

    system_prompt = """
You are an expert in the National Construction Code (NCC) / Building Code of Australia (BCA).

You will be given:
- The user's task (e.g. "Find stair and balustrade requirements for a new Class 1 dwelling").
- The HTML of one or more NCC/BCA clause pages, as plain text.

Your job:
- Identify the key code requirements that are relevant to the userâ€™s task,
  focusing on new construction (not only existing building exceptions).
- Use the NCC 2022 edition as your default assumption unless the text clearly
  indicates a different edition.
- Summarise the requirements in clear, non-legal language.

You MUST:
- Fill the BCARequirementReport schema.
- Provide concise requirement statements (not entire clause text).
- Include code references where visible (e.g. "NCC 2022 Vol 2 Part 3.9.1").
- List any important assumptions you made (e.g. building class, volume).

This is informational guidance only, not legal advice.
"""

    user_prompt = f"""
User task:
{user_task}

NCC/BCA HTML (truncated plain text):
\"\"\"{html_snippet}\"\"\"
"""

    completion = client.beta.chat.completions.parse(
        model="gpt-4o-mini-2024-07-18",
        temperature=0.2,
        messages=[
            {"role": "system", "content": system_prompt},
            {"role": "user", "content": user_prompt},
        ],
        response_format=BCARequirementReport,
    )

    return completion.choices[0].message.parsed

async def run_bca_ncc_agent(user_task: str, max_steps: int = 10) -> BCARequirementReport:
    """
    High-level helper:
    1) Run the NCC agent to navigate and extract relevant HTML.
    2) Summarise that HTML into a structured BCARequirementReport.
    """
    html, screenshot_data = await ncc_bca_agent_get_html(user_task=user_task, max_steps=max_steps)
    # The screenshot_data is now available if needed for further processing.
    report = summarize_bca_requirements(html, user_task)
    return report

!apt-get install -y libatk1.0-0 libatk-bridge2.0-0 libatspi2.0-0 libxcomposite1

user_task = "Find stair and balustrade requirements for a new Class 1 dwelling in NCC 2022 Volume Two."

report = await run_bca_ncc_agent(user_task, max_steps=8)

print("=== Assumptions ===")
for a in report.assumptions:
    print("- ", a)

print("\n=== Requirements ===")
for r in report.requirements:
    print(f"\n[{r.category}] {r.code_reference or 'No ref'}")
    print("Requirement:", r.requirement)
    if r.applicability:
        print("Applies to:", r.applicability)
    if r.notes:
        print("Notes:", r.notes)





